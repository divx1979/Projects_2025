{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-14T09:12:16.981898Z","iopub.execute_input":"2025-07-14T09:12:16.982305Z","iopub.status.idle":"2025-07-14T09:12:17.820670Z","shell.execute_reply.started":"2025-07-14T09:12:16.982267Z","shell.execute_reply":"2025-07-14T09:12:17.817754Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"1. Notebook: 01_data_prep\n\nIngest raw comments, clean, de‐duplicate, and save as Bronze table","metadata":{}},{"cell_type":"code","source":"# 01_data_prep\n\n# Install dependencies once per cluster\n# %pip install -q sentence-transformers requests mlflow\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, when\nimport pandas as pd\n\nspark = SparkSession.builder.getOrCreate()\n\n# 1. Read source table\nbronze = spark.read.table(\"gold_dev.unified_posts_comments_testing\") \\\n    .selectExpr(\n        \"platform\",\"post_id\",\"post_user_id\",\"post_content\",\"media_type\",\"media_url\",\n        \"post_created_time\",\"post_load_timestamp\",\"comment_load_timestamp\",\"comment_id\",\n        \"comment_user_id\",\"comment_text\",\"comment_created_time\",\"load_timestamp\",\n        \"post_sentiment_score_positive\",\"post_sentiment_score_negative\",\n        \"post_sentiment_score_neutral\",\"post_predicted_sentiment\",\n        \"comment_sentiment_score_positive\",\"comment_sentiment_score_negative\",\n        \"comment_sentiment_score_neutral\",\"comment_predicted_sentiment\",\n        \"createdOn\",\"createdBy\",\"updatedOn\",\"updatedBy\",\n        \"businessEntityId\",\"businessEntityName\",\n        \"businessFunctionId\",\"businessFunctionName\",\"keywords_list\",\"category\",\n        \"date_key\",\"ReviewerName\",\"siteID\"\n    )\n\n# 2. Clean & de-dup\nbronze_clean = bronze \\\n    .withColumn(\"comment_text\", when(col(\"comment_text\").isNull(), \"\").otherwise(col(\"comment_text\"))) \\\n    .dropDuplicates([\"comment_text\", \"comment_id\"])\n\n# 3. Write Bronze\nbronze_clean.write.mode(\"overwrite\").saveAsTable(\"ml_bronze.comments_clean\")\ndisplay(bronze_clean.limit(5))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"2. Notebook: 02_feature_engineering\n\nSBERT + GPT mapping, feature engineering for sales-weather tasks (LIVC1703). Saves Silver table","metadata":{}},{"cell_type":"code","source":"# 02_feature_engineering\n\nimport mlflow\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import pandas_udf, PandasUDFType\nimport pandas as pd\nimport requests, time\nfrom sentence_transformers import SentenceTransformer, util\n\nspark = SparkSession.builder.getOrCreate()\n\n# Load cleaned comments\ndf = spark.read.table(\"ml_bronze.comments_clean\").toPandas()\n\n# 1) SBERT Mapping\ncat_defs = {\n    \"Food Quality\":\"taste,freshness,quality of food\",\n    \"Ambiance\":\"atmosphere,lighting,seating,music\",\n    \"Service\":\"staff behavior,speed,hospitality\",\n    \"Value for Money\":\"pricing,portion size\",\n    \"Communication\":\"ordering and communication\"\n}\ncats, texts = list(cat_defs.keys()), list(cat_defs.values())\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\ncat_emb = model.encode(texts, convert_to_tensor=True)\nembs = model.encode(df['comment_text'].tolist(), convert_to_tensor=True, batch_size=64)\nscores = util.cos_sim(embs, cat_emb)\nbest = scores.argmax(dim=1).cpu().numpy()\ndf['sbert_cat'] = [cats[i] for i in best]\n\n# 2) GPT Mapping (Retail Category)\nAZURE_ENDPOINT=\"https://...openai.azure.com\"\nDEPLOYMENT=\"gpt-35-turbo\"; API_VER=\"2024-02-01\"; API_KEY=\"...\"\nurl=f\"{AZURE_ENDPOINT}/openai/deployments/{DEPLOYMENT}/chat/completions?api-version={API_VER}\"\nhdr={\"Content-Type\":\"application/json\",\"api-key\":API_KEY}\nretail_cats=[...your list...]\nfmt_cats=\"\\n\".join(f\"- {c}\" for c in retail_cats)\n\ndef classify_retail(comment):\n    if not comment.strip(): return \"NoComment\"\n    p = f\"Categories:\\n{fmt_cats}\\nComment: “{comment}”\\nReply only with one category.\"\n    payload={\"messages\":[{\"role\":\"user\",\"content\":p}],\"max_tokens\":20,\"temperature\":0.0}\n    for _ in range(3):\n        r = requests.post(url, headers=hdr, json=payload)\n        if r.ok:\n            return r.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n        time.sleep(2)\n    return \"Error\"\n\ndf['retail_cat'] = df['comment_text'].apply(classify_retail)\n\n# 3) Persist Silver\nsilver = spark.createDataFrame(df)\nsilver.write.mode(\"overwrite\").saveAsTable(\"ml_silver.comments_features\")\ndisplay(silver.limit(5))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"3. Notebook: 03_train_register\n\nTrain simple classifier (e.g., logistic regression on SBERT+features), log with MLflow, register model","metadata":{}},{"cell_type":"code","source":"# 03_train_register\n\nimport mlflow, mlflow.sklearn\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.linalg import Vectors\n\nspark = SparkSession.builder.getOrCreate()\n\n# Read Silver data\ndf = spark.read.table(\"ml_silver.comments_features\").toPandas()\n\n# Example: train a model to predict SBERT category from SBERT embeddings\n# (In practice, you'd save embeddings in DF. Here, re-encode small sample.)\nfrom sentence_transformers import SentenceTransformer\nmod = SentenceTransformer('all-MiniLM-L6-v2')\nembs = mod.encode(df['comment_text'].tolist())\nX = pd.DataFrame(embs)\ny = df['sbert_cat']\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nXtr,Xte,ytr,yte = train_test_split(X,y,test_size=0.2,random_state=42)\n\n# MLflow experiment\nmlflow.set_experiment(\"SentimentCategorization\")\nwith mlflow.start_run():\n    clf = LogisticRegression(max_iter=200)\n    clf.fit(Xtr, ytr)\n    acc = clf.score(Xte,yte)\n    mlflow.log_metric(\"accuracy\", acc)\n    mlflow.sklearn.log_model(clf, \"sbert_clf\", registered_model_name=\"SentimentCatModel\")\n    print(\"Registered model with accuracy:\", acc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4. Notebook: 04_inference\n\nLoad registered model, score new data, write predictions to Gold table","metadata":{}},{"cell_type":"code","source":"# 04_inference\n\nimport mlflow\nimport pandas as pd\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\n\n# Load model\nmodel_uri = \"models:/SentimentCatModel/Production\"\nclf = mlflow.sklearn.load_model(model_uri)\n\n# Load new comments from Silver\ndf = spark.read.table(\"ml_silver.comments_features\").toPandas()\nfrom sentence_transformers import SentenceTransformer\nembedder = SentenceTransformer('all-MiniLM-L6-v2')\nX = embedder.encode(df['comment_text'].tolist())\n\n# Predict\ndf['predicted_cat'] = clf.predict(X)\n\n# Write to Gold\ngold_df = spark.createDataFrame(df)\ngold_df.write.mode(\"overwrite\").saveAsTable(\"gold_dev.sentiment_predictions\")\ndisplay(gold_df.limit(5))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"5. MLOps Pipeline (Azure DevOps YAML)\n\nThis ci-pipeline builds, tests, and deploys the notebooks as jobs in Databricks and registers models","metadata":{}},{"cell_type":"code","source":"# azure-pipelines.yml\ntrigger:\n- main\n\nvariables:\n  DATABRICKS_HOST: $(databricksHost)\n  DATABRICKS_TOKEN: $(databricksToken)\n\nstages:\n- stage: Build\n  jobs:\n  - job: Test_Notebooks\n    pool: ubuntu-latest\n    steps:\n    - script: |\n        # run notebooks in headless mode to catch errors\n        databricks workspace import_dir . /Repos/$(Build.Repository.Name)\n        databricks runs submit --json-file ci/config_test_run.json\n      displayName: \"Test Notebooks on Databricks\"\n\n- stage: Train\n  dependsOn: Build\n  jobs:\n  - job: Train_Model\n    pool: ubuntu-latest\n    steps:\n    - script: |\n        databricks runs submit --json-file ci/config_train_run.json\n      displayName: \"Train & Register Model\"\n\n- stage: Deploy\n  dependsOn: Train\n  jobs:\n  - job: Deploy_Inference\n    pool: ubuntu-latest\n    steps:\n    - script: |\n        databricks jobs create --json-file ci/config_inference_job.json --overwrite\n      displayName: \"Schedule Inference Job\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Example ci/config_test_run.json","metadata":{}},{"cell_type":"code","source":"{\n  \"run_name\": \"CI Test Run\",\n  \"existing_cluster_id\": \"<CLUSTER_ID>\",\n  \"notebook_task\": {\n    \"notebook_path\": \"/Repos/$(Build.Repository.Name)/01_data_prep\"\n  }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Example ci/config_train_run.json","metadata":{}},{"cell_type":"code","source":"{\n  \"run_name\": \"Train Sentiment Model\",\n  \"existing_cluster_id\": \"<CLUSTER_ID>\",\n  \"notebook_task\": {\n    \"notebook_path\": \"/Repos/$(Build.Repository.Name)/03_train_register\"\n  }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Example ci/config_inference_job.json","metadata":{}},{"cell_type":"code","source":"{\n  \"name\": \"Daily Sentiment Inference\",\n  \"existing_cluster_id\": \"<CLUSTER_ID>\",\n  \"schedule\": {\n    \"quartz_cron_expression\": \"0 0 * * * ? *\",\n    \"timezone_id\": \"UTC\"\n  },\n  \"notebook_task\": {\n    \"notebook_path\": \"/Repos/$(Build.Repository.Name)/04_inference\"\n  }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"What You’ll Have:\n\t1.\tBronze/Silver/Gold tables in your Databricks metastore.\n\t2.\tSBERT + GPT mapping pipelines.\n\t3.\tMLflow-managed model with registration and versioning.\n\t4.\tDatabricks Jobs scheduled daily for inference.\n\t5.\tCI/CD via Azure DevOps (or adapt to GitHub Actions) to enforce code quality and automate retraining/deployment.\n\nYou can plug in your own cluster IDs, tokens, and keys. This framework delivers a production-grade MLOps workflow on Azure Databrick","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}